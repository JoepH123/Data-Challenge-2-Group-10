{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sqlite3 as sq\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "# Mean absolute percent error\n",
    "def MAPE(Y_true,Y_Predicted):\n",
    "    mape = np.mean(np.abs((Y_true - Y_Predicted)/Y_true))*100\n",
    "    return mape\n",
    "# Simple percent split --- !!! applies log to train_y\n",
    "# would be good to add param for choosing split\n",
    "def per_split(df):\n",
    "    ave_crime = df['Number of crimes'].mean()\n",
    "    train = df.iloc[:100]\n",
    "    test = df.iloc[100:].fillna(ave_crime)\n",
    "    train_x = train[['Number of crimes', 1]] #1: year, including year increases mape by 13.9966 - 11.7564 percent\n",
    "    train_y = train['next_num_crimes'].apply(lambda cell: ave_crime if cell == np.nan else np.log10(cell))\n",
    "    test_x = test[['Number of crimes', 1]]\n",
    "    test_y = test['next_num_crimes']\n",
    "    return train_x, train_y, test_x, test_y\n",
    "def per_split_in(df, split):\n",
    "    ave_crime = df['Number of crimes'].mean()\n",
    "    train = df.iloc[:split]\n",
    "    test = df.iloc[split:].fillna(ave_crime)\n",
    "    train_x = train[['Number of crimes', 1, 0]] #1: year, including year increases mape by 13.9966 - 11.7564 percent\n",
    "    train_y = train['next_num_crimes'].apply(lambda cell: ave_crime if cell == np.nan else np.log10(cell))\n",
    "    test_x = test[['Number of crimes', 1, 0]]\n",
    "    test_y = test['next_num_crimes']\n",
    "    return train_x, train_y, test_x, test_y\n",
    "def eval(test_y, pred):\n",
    "    mae = mean_absolute_error(test_y, pred)\n",
    "    mape = MAPE(test_y, pred)\n",
    "    rsme = sqrt(mean_squared_error(test_y, pred))\n",
    "    print(f'MAE: {mae}, MAPE: {mape},RSME: {rsme}')\n",
    "# log = lambda cell: ave_crime if cell == np.nan else np.log10(cell)\n",
    "undo_log = np.vectorize(lambda x: 10 ** x)\n",
    "\n",
    "df_police_force = pd.read_csv('police force dataset grouped and preprocessed.csv', sep=';')\n",
    "\n",
    "def police_force_to_time_series(df):\n",
    "    # Input police force\n",
    "    x = input('Which police force?')\n",
    "\n",
    "    filtered = df[df['Falls within'] == x]\n",
    "    df = filtered.groupby('County')['COUNT(*)'].sum()\n",
    "    df = df.to_frame()\n",
    "    df.reset_index(inplace=True)\n",
    "    max_value = df['COUNT(*)'].max()\n",
    "    list_counties = []\n",
    "    # Adding all the counties that have equal to or greater than 10% of the crimes of the max county.\n",
    "    for i in range(len(df)):\n",
    "        if df.loc[i, 'COUNT(*)'] > (max_value / 10):\n",
    "            # Prevalent county if more than 10 percent of county with most crimes in the county.\n",
    "            list_counties.append(df.loc[i, 'County'])\n",
    "\n",
    "    # Append the other category to the list_counties\n",
    "    list_counties.append('Other')\n",
    "\n",
    "    list_df_ts = []\n",
    "    # Making time series dataframes for each county\n",
    "    for county in list_counties:\n",
    "        county_df = filtered[filtered['County'] == county]\n",
    "        count_per_month_for_county = county_df.groupby('Month')['COUNT(*)'].sum()\n",
    "        count_per_month_for_county = count_per_month_for_county.to_frame()\n",
    "        count_per_month_for_county.reset_index(inplace=True)\n",
    "        count_per_month_for_county = count_per_month_for_county.rename(columns={'COUNT(*)': 'Number of crimes'})\n",
    "        # Change to datetime, in order to make it a valid time series\n",
    "        count_per_month_for_county['Month'] = pd.to_datetime(count_per_month_for_county['Month'])\n",
    "        list_df_ts.append((county, count_per_month_for_county))\n",
    "\n",
    "    return list_df_ts\n",
    "from sklearn import metrics\n",
    "\n",
    "def r2_adj_from_r2(r2,n,k = 3):\n",
    "    #n is the number of values (samples) in the data\n",
    "    #k is the number of variables in the data --> normally 1, namely the time\n",
    "    a1= (1-r2) * (1-n)\n",
    "    a2= n-k-1\n",
    "    a3= 1\n",
    "    r2_adj = a3 - (a1/a2)\n",
    "    return r2_adj\n",
    "\n",
    "# Performance measures based on y_true and y_pred\n",
    "def timeseries_evaluation_metrics_func(y_true, y_pred):\n",
    "    def mean_absolute_percentage_error(y_true, y_pred):\n",
    "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    print(f'Number of months in test data: {len(y_true)}')\n",
    "    print('Evaluation metric results:-')\n",
    "    print(f'(Mean Squared Error) MSE is : {metrics.mean_squared_error(y_true, y_pred)}')\n",
    "    print(f'(Mean Absolute Error) MAE is : {metrics.mean_absolute_error(y_true, y_pred)}')\n",
    "    print(f'(Root Mean Square Error) RMSE is : {np.sqrt(metrics.mean_squared_error(y_true, y_pred))}')\n",
    "    print(f'(Mean Absolute Percentage Error) MAPE is : {mean_absolute_percentage_error(y_true, y_pred)}')\n",
    "    # Computing R^2 by hand:\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mean_true = y_true.mean()\n",
    "    R2 = 1 - (sum((y_true - y_pred)**2) / sum((y_true - mean_true)**2))\n",
    "    # Same result with\n",
    "    print(f'(R-Squared) R2 is : {R2}')\n",
    "    adj_R2 = r2_adj_from_r2(R2,len(y_pred))\n",
    "    print(f'(adjusted R-Squared) adj-R2 is : {adj_R2}',end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which police force?Avon and Somerset Constabulary\n"
     ]
    }
   ],
   "source": [
    "\n",
    "list_ts = police_force_to_time_series(df_police_force) # Avon and Somerset Constabulary\n",
    "\n",
    "ts_county = list_ts[1][1]\n",
    "ts_county['Number of crimes'] = ts_county['Number of crimes'].astype(float)\n",
    "ts_month_as_index = ts_county.set_index('Month')\n",
    "months = [x.month for x in ts_month_as_index.index]\n",
    "years = [x.year for x in ts_month_as_index.index]\n",
    "X = pd.DataFrame(np.array([months, years]).T)\n",
    "ts_county['next_num_crimes'] = ts_county['Number of crimes'].shift(-1)\n",
    "\n",
    "ave_crime = ts_county['Number of crimes'].mean()\n",
    "log = lambda cell: ave_crime if cell == np.nan else np.log10(cell)\n",
    "\n",
    "ts_county['next_num_crimes'].fillna(ts_county['next_num_crimes'].mean(), inplace = True)\n",
    "t = X.join(ts_county)   # include year in prediction (year and month but month makes it worse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25] TEST: [26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15176/3994013472.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# print(mean_absolute_error(data['log_dif'][26:], forecasts[26:]))   # attempt to eval model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mar_log_dif\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchain_ar_logdif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0mundo_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar_log_dif\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m111\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15176/3994013472.py\u001b[0m in \u001b[0;36mchain_ar_logdif\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mtrain_end\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_arima\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'log'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrain_end\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Month'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseasonal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FIRST MODEL'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Geopandas\\lib\\site-packages\\pmdarima\\arima\\auto.py\u001b[0m in \u001b[0;36mauto_arima\u001b[1;34m(y, X, start_p, d, start_q, max_p, max_d, max_q, start_P, D, start_Q, max_P, max_D, max_Q, max_order, m, seasonal, stationary, information_criterion, alpha, test, seasonal_test, stepwise, n_jobs, start_params, trend, method, maxiter, offset_test_args, seasonal_test_args, suppress_warnings, error_action, trace, random, random_state, n_fits, return_valid_fits, out_of_sample_size, scoring, scoring_args, with_intercept, sarimax_kwargs, **fit_args)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mD\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# we don't have a D yet and we need one (seasonal)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m         D = nsdiffs(xx, m=m, test=seasonal_test, max_D=max_D,\n\u001b[1;32m--> 523\u001b[1;33m                     **seasonal_test_args)\n\u001b[0m\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mD\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Geopandas\\lib\\site-packages\\pmdarima\\arima\\utils.py\u001b[0m in \u001b[0;36mnsdiffs\u001b[1;34m(x, m, max_D, test, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mdodiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Geopandas\\lib\\site-packages\\pmdarima\\arima\\seasonality.py\u001b[0m in \u001b[0;36mestimate_seasonal_differencing_term\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[1;31m# Get the critical value for m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m         \u001b[0mstat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_test_statistic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m         \u001b[0mcrit_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_calc_ocsb_crit_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstat\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mcrit_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Geopandas\\lib\\site-packages\\pmdarima\\arima\\seasonality.py\u001b[0m in \u001b[0;36m_compute_test_statistic\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mlag_term\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlag\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 1 -> maxlag (incl)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m                     \u001b[0mfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_ocsb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlag_term\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m                     \u001b[0mfits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m                     \u001b[0micvals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0micfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Geopandas\\lib\\site-packages\\pmdarima\\arima\\seasonality.py\u001b[0m in \u001b[0;36m_fit_ocsb\u001b[1;34m(x, m, lag, max_lag)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[1;31m# the linear model's constructor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[0mmf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mylag\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m         \u001b[0mar_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'qr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;31m# Create Z4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Geopandas\\lib\\site-packages\\statsmodels\\tools\\tools.py\u001b[0m in \u001b[0;36madd_constant\u001b[1;34m(data, prepend, has_constant)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Only implemented for 2-dimensional arrays'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m     \u001b[0mis_nonzero_const\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mptp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m     \u001b[0mis_nonzero_const\u001b[0m \u001b[1;33m&=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_nonzero_const\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mptp\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Geopandas\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mptp\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   2628\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2629\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mptp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2630\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_methods\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ptp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Geopandas\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_ptp\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_ptp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     return um.subtract(\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[0mumr_maximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m         \u001b[0mumr_minimum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "def chain_ar_logdif(data):\n",
    "    \"\"\"input: df w/ 'Month', 'Number of crimes', 'next_num_crimes'\n",
    "    return: ar model for log dif\n",
    "        \"\"\"\n",
    "    #data['log_dif'] = data['next_num_crimes'].apply(log) - data['Number of crimes'].apply(log)\n",
    "    data['log'] = data['Number of crimes'].apply(log)\n",
    "    data['next_num_crimes'].fillna(data['next_num_crimes'].mean(), inplace = True)\n",
    "    #data['log_dif'].fillna(data['log_dif'].mean(), inplace = True)\n",
    "\n",
    "    ts_split = TimeSeriesSplit(n_splits=5)\n",
    "    #ts_mean = data['log_dif'][:26].mean()\n",
    "    ts_mean = data['log'][:26].mean()\n",
    "    forecasts = np.full(26, ts_mean)  # first 25 \"predictions\" = mean # of crimes -- makes graph nicer / fix indexing\n",
    "    i = 0\n",
    "    for train_index, test_index in ts_split.split(data['Number of crimes']):\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        train_end = train_index[-1]\n",
    "        if i ==0:\n",
    "            model = pm.auto_arima(data['log'].iloc[:train_end], x='Month', seasonal=True, m=12)\n",
    "            i = 1\n",
    "            print('FIRST MODEL')\n",
    "        else:\n",
    "\n",
    "            model.update(data['log'].iloc[:train_end], x='Month')\n",
    "            i += 1\n",
    "            print(f'MODEL: {i}')\n",
    "        forecast = model.predict(len(test_index))\n",
    "        forecasts = np.append(forecasts, forecast)\n",
    "        print(forecast, forecasts)\n",
    "        timeseries_evaluation_metrics_func(undo_log(data['log'].iloc[train_end:test_index[-1]]), undo_log(forecast))\n",
    "\n",
    "    plt.plot(pd.Series(forecasts), c='blue')\n",
    "    plt.plot(data['log'], c='red')\n",
    "    plt.show()\n",
    "    # print(mean_absolute_error(data['log_dif'][26:], forecasts[26:]))   # attempt to eval model\n",
    "    return model\n",
    "ar_log_dif = chain_ar_logdif(t)\n",
    "undo_log(ar_log_dif.predict(5))\n",
    "x = 111\n",
    "test_one = ar_log_dif.update(t['log'].iloc[:x], x='Month')\n",
    "timeseries_evaluation_metrics_func(t['Number of crimes'].iloc[x:], undo_log(test_one.predict(18)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.01214\tvalidation_1-rmse:5074.93506\n",
      "MAE: 288.498568509639, MAPE: 6.052369407703416,RSME: 387.6981405579882\n"
     ]
    }
   ],
   "source": [
    "def rf_reg(data, train_size):\n",
    "    \"\"\"\n",
    "    :param data:\n",
    "    requires columns: 1, num crimes, next num\n",
    "    :return:\n",
    "    rf regressor model\n",
    "    \"\"\"\n",
    "    train_x, train_y, test_x, test_y = per_split_in(data, train_size) # 120 -> mape: 4.8 increase training means less test data -> super accurate\n",
    "    xgb_model = xgb.XGBRFRegressor().fit(train_x, train_y,\n",
    "                                         eval_set=[(train_x, train_y), (test_x, test_y)])\n",
    "    # evals_result = xgb_model.evals_result()\n",
    "    # print(evals_result)\n",
    "    # pred = xgb_model.predict(test_x)\n",
    "    # eval(test_y, undo_log(xgb_model.predict(test_x)))\n",
    "    return xgb_model, test_x, test_y\n",
    "rf_model, test_x, test_y = rf_reg(t, 90)\n",
    "pred = undo_log(rf_model.predict(test_x))\n",
    "eval(test_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_police_force = pd.read_csv('police force dataset grouped and preprocessed.csv', sep=';')\n",
    "df_police_force_p_month = df_police_force.groupby('Month')['COUNT(*)'].sum()\n",
    "df_police_force_p_month = df_police_force_p_month.to_frame()\n",
    "df_police_force_p_month.reset_index(inplace = True)\n",
    "df_police_force_p_month = df_police_force_p_month.rename(columns = {'COUNT(*)': 'Number of crimes'})\n",
    "# Change to datetime, in order to make it a valid time series\n",
    "df_police_force_p_month['Month'] = pd.to_datetime(df_police_force_p_month['Month'], format=\"%Y-%m\", exact=True)\n",
    "\n",
    "df_police_force_p_month['next_num_crimes'] = df_police_force_p_month['Number of crimes'].shift(-1)\n",
    "\n",
    "month_index = df_police_force_p_month.set_index('Month')\n",
    "months = [x.month for x in month_index.index]\n",
    "years = [x.year for x in month_index.index]\n",
    "X = pd.DataFrame(np.array([months, years]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
